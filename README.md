# YT-Short-Clipper

ğŸ¬ **Automated YouTube to Short-Form Content Pipeline**

Transform long-form YouTube videos (podcasts, interviews, vlogs) into engaging short-form content for TikTok, Instagram Reels, and YouTube Shorts â€” all with a single command.

## ğŸ–¥ï¸ Desktop App (Recommended)

Download the portable desktop app â€” no Python or FFmpeg installation required!

### Quick Start

1. Download `AutoClipper-v1.0.zip` from [Releases](../../releases)
2. Extract to any folder
3. Run `AutoClipper.exe`
4. Enter your OpenAI or Azure OpenAI API key and click "Validate"
5. For Azure OpenAI, update the "Base URL" to your Azure endpoint
6. Paste YouTube URL, set number of clips, and click "Start Processing"

### Desktop App Features

- âœ… **No installation required** â€” portable single folder
- âœ… **Simple GUI** â€” just paste URL and click process
- âœ… **OpenAI & Azure OpenAI support** â€” use either API provider
- âœ… **API key validation** â€” instant feedback if key is valid
- âœ… **Real-time progress** â€” download percentage, processing status
- âœ… **Token usage tracking** â€” see GPT tokens, Whisper minutes, TTS chars used
- âœ… **Cost estimation** â€” estimated API cost per session

### Desktop App Contents

```
AutoClipper/
â”œâ”€â”€ AutoClipper.exe     # Main application
â”œâ”€â”€ ffmpeg/
â”‚   â””â”€â”€ ffmpeg.exe      # Bundled FFmpeg
â”œâ”€â”€ yt-dlp.exe          # Bundled yt-dlp
â”œâ”€â”€ output/             # Output clips folder
â””â”€â”€ config.json         # Saved settings (auto-created)
```

---

## ğŸ’» CLI Version

For advanced users who prefer command line or want to customize the pipeline.

## âœ¨ Features

- **ğŸ¥ Auto Download** - Downloads YouTube videos with Indonesian subtitles using yt-dlp
- **ğŸ” AI Highlight Detection** - Uses GPT-4 to identify the most engaging segments (60-120 seconds)
- **âœ‚ï¸ Smart Clipping** - Automatically cuts video at optimal timestamps
- **ğŸ“± Portrait Conversion** - Converts landscape (16:9) to portrait (9:16) with intelligent speaker tracking
- **ğŸ¯ Face Detection** - Tracks speakers and switches focus based on who's talking
- **ğŸª Hook Generation** - Creates attention-grabbing intro scenes with AI-generated text and TTS voiceover
- **ğŸ“ Auto Captions** - Adds CapCut-style word-by-word highlighted captions using Whisper
- **ğŸ“Š SEO Metadata** - Generates optimized titles and descriptions for each clip

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        YT-Short-Clipper                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ YouTube  â”‚â”€â”€â”€â–¶â”‚  Downloader  â”‚â”€â”€â”€â–¶â”‚  Subtitle   â”‚           â”‚
â”‚  â”‚   URL    â”‚    â”‚   (yt-dlp)   â”‚    â”‚   Parser    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                              â”‚                  â”‚
â”‚                                              â–¼                  â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                                    â”‚ Highlight Finderâ”‚         â”‚
â”‚                                    â”‚    (GPT-4)      â”‚         â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                              â”‚                  â”‚
â”‚                                              â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Video Processing                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚   Clipper  â”‚â”€â–¶â”‚  Portrait  â”‚â”€â–¶â”‚  Hook Generator    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  (FFmpeg)  â”‚  â”‚ Converter  â”‚  â”‚  (TTS + Overlay)   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                              â”‚            â”‚  â”‚
â”‚  â”‚                                              â–¼            â”‚  â”‚
â”‚  â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚                                    â”‚Caption Generatorâ”‚    â”‚  â”‚
â”‚  â”‚                                    â”‚   (Whisper)    â”‚     â”‚  â”‚
â”‚  â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                              â”‚                  â”‚
â”‚                                              â–¼                  â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                                    â”‚  Output Clips   â”‚         â”‚
â”‚                                    â”‚  + Metadata     â”‚         â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requirements

### System Dependencies

| Dependency | Version | Purpose |
|------------|---------|---------|
| Python | 3.10+ | Runtime |
| FFmpeg | 4.4+ | Video processing |
| yt-dlp | Latest | YouTube downloading |

### Python Dependencies

```
openai>=1.0.0
python-dotenv>=1.0.0
opencv-python>=4.8.0
numpy>=1.24.0
```

> **Note:** The desktop app uses OpenAI Whisper API instead of local Whisper model, so `openai-whisper` is not required for the desktop version.

### API Keys

You can use either OpenAI or Azure OpenAI:

| Provider | API Key | Required Models |
|----------|----------|----------------|
| **OpenAI** | `OPENAI_APIKEY` | GPT-4, TTS-1, Whisper-1 |
| **Azure OpenAI** | `AZURE_OPENAI_API_KEY` + endpoint + deployment names | gpt-4, tts, whisper |

> See [Azure OpenAI Setup](#azure-openai-setup) for detailed Azure configuration.

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/yt-short-clipper.git
cd yt-short-clipper
```

### 2. Install System Dependencies

**Windows (using Chocolatey):**
```powershell
choco install ffmpeg yt-dlp
```

**macOS (using Homebrew):**
```bash
brew install ffmpeg yt-dlp
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
pip install yt-dlp
```

### 3. Install Python Dependencies

```bash
pip install openai python-dotenv opencv-python numpy openai-whisper
```

Or using requirements.txt:
```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the project root:

```env
OPENAI_APIKEY=your_openai_api_key_here
```

## Azure OpenAI Setup

### Option 1: Using Azure OpenAI instead of OpenAI

If you prefer to use Azure OpenAI instead of the OpenAI API, configure the following environment variables in your `.env` file:

```env
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your-azure-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Azure deployment names (must match your Azure OpenAI deployment names)
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4
AZURE_OPENAI_TTS_DEPLOYMENT=tts
AZURE_OPENAI_WHISPER_DEPLOYMENT=whisper
```

### Azure OpenAI Prerequisites

1. **Create Azure OpenAI Resource**
   - Go to [Azure Portal](https://portal.azure.com)
   - Create a new "Azure OpenAI" resource
   - Select your region and pricing tier
   - Wait for deployment to complete

2. **Deploy Required Models**
   - In your Azure OpenAI resource, go to "Deployments"
   - Deploy the following models:
     - **Chat**: `gpt-4` (or `gpt-4o`, `gpt-4o-mini`)
     - **Text-to-Speech**: `tts` (Azure OpenAI Speech service)
     - **Whisper**: `whisper` (for transcription)
   - Note down the deployment names you assign to each model

3. **Get API Keys and Endpoint**
   - Go to "Keys and Endpoint" in your Azure OpenAI resource
   - Copy your API key and endpoint URL

4. **Configure `.env` File**
   - Use the Azure OpenAI variables instead of `OPENAI_APIKEY`
   - The application will automatically detect and use Azure OpenAI when configured

### Desktop App with Azure OpenAI

The desktop app supports Azure OpenAI as well:

1. Run `AutoClipper.exe`
2. In the configuration panel, enter:
   - **API Key**: Your Azure OpenAI API key
   - **Base URL**: Your Azure OpenAI endpoint (e.g., `https://your-resource.openai.azure.com/openai/deployments/gpt-4`)
   - **Model**: Your chat deployment name (e.g., `gpt-4`)
3. Click "Validate" to test the connection

### Note on TTS and Whisper

For Azure OpenAI:
- **TTS**: Uses Azure Cognitive Services Speech API. Ensure you have the Speech service deployed.
- **Whisper**: Use Azure OpenAI Whisper deployment or local Whisper model with `openai-whisper` package.

## ğŸ“– Usage

### Quick Start (All-in-One)

The main script handles the entire pipeline:

```bash
# Interactive mode
python auto-clipper/main.py

# Command line mode
python auto-clipper/main.py <youtube_url> [num_clips]

# Example
python auto-clipper/main.py "https://www.youtube.com/watch?v=xxxxx" 5
```

### Individual Modules

You can also use each module separately:

#### 1. Download Video + Subtitle

```bash
python auto-clipper/downloader.py <youtube_url>
```

**Output:** `downloads/video_title.mp4` + `downloads/video_title.id.srt`

#### 2. Find Highlights

```bash
python auto-clipper/highlight_finder.py <srt_file> [num_clips]
```

**Output:** `downloads/video_title.highlights.json`

#### 3. Clip Video

```bash
python auto-clipper/video_clipper.py <video_file> <highlights_json>
```

**Output:** `clips/clip_01_title.mp4`, `clips/clip_02_title.mp4`, ...

#### 4. Convert to Portrait

```bash
python auto-clipper/portrait_converter.py <input_video> [output_video]
```

**Output:** `input_portrait.mp4`

#### 5. Add Captions

```bash
python auto-clipper/caption_generator.py <input_video> [output_video] [model_size]
```

**Model sizes:** `tiny`, `base`, `small`, `medium`, `large`

**Output:** `input_captioned.mp4`

#### 6. Add Hook Scene

```bash
python auto-clipper/hook_generator.py <clip_path> "<hook_text>"
```

**Output:** `clip_hooked.mp4`

## ğŸ“ Output Structure

```
output/
â”œâ”€â”€ _temp/                          # Temporary files (source video, subtitles)
â”‚   â”œâ”€â”€ source.mp4
â”‚   â”œâ”€â”€ source.id.srt
â”‚   â””â”€â”€ video_info.json
â”‚
â”œâ”€â”€ 20240115-143001/               # Clip folder (timestamp-based)
â”‚   â”œâ”€â”€ master.mp4                 # Final clip (portrait + hook + captions)
â”‚   â””â”€â”€ data.json                  # Metadata (title, description, timestamps)
â”‚
â”œâ”€â”€ 20240115-143002/
â”‚   â”œâ”€â”€ master.mp4
â”‚   â””â”€â”€ data.json
â”‚
â””â”€â”€ ...
```

### data.json Structure

```json
{
  "title": "ğŸ”¥ Momen Kocak Saat Pembully Datang Minta Maaf",
  "description": "Siapa sangka mantan pembully malah datang minta endorse! ğŸ˜‚ #podcast #viral #fyp",
  "original_title": "Mantan Pembully Datang ke Rumah",
  "hook_text": "Mantan pembully TIARA datang ke rumah minta endorse salad buah",
  "hook_duration": 3.5,
  "start_time": "00:15:23,000",
  "end_time": "00:17:05,000",
  "duration_seconds": 102.0,
  "hook_added": true
}
```

## âš™ï¸ Configuration

### Highlight Detection Parameters

In `main.py` and `highlight_finder.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `num_clips` | 5 | Number of clips to generate |
| `min_duration` | 60s | Minimum clip duration |
| `max_duration` | 120s | Maximum clip duration |
| `target_duration` | 90s | Ideal clip duration |

### Portrait Conversion Parameters

In `portrait_converter.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `output_resolution` | 1080x1920 | Output video resolution |
| `min_frames_before_switch` | 210 | Frames before speaker switch (~7s at 30fps) |
| `switch_threshold` | 3.0 | Movement multiplier to trigger switch |

### Caption Parameters

In `caption_generator.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `model_size` | base | Whisper model (tiny/base/small/medium/large) |
| `language` | id | Transcription language |
| `chunk_size` | 4 | Words per caption line |

### Hook Generation Parameters

In `hook_generator.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `tts_voice` | nova | OpenAI TTS voice (nova/shimmer/alloy) |
| `tts_speed` | 1.0 | Speech speed |
| `max_words` | 15 | Maximum words in hook text |

## ğŸ”§ How It Works

### 1. Video Download
- Uses yt-dlp to download video in best quality (max 1080p)
- Automatically fetches Indonesian auto-generated subtitles
- Extracts video metadata (title, description, channel)

### 2. Highlight Detection
- Parses SRT subtitle file with timestamps
- Sends transcript to GPT-4 with specific criteria:
  - Punchlines and funny moments
  - Interesting insights
  - Emotional/dramatic moments
  - Memorable quotes
  - Complete story arcs
- Validates duration (60-120 seconds)
- Generates hook text for each highlight

### 3. Portrait Conversion
- Uses OpenCV Haar Cascade for face detection
- Tracks lip movement to identify active speaker
- Implements "camera cut" style switching (not smooth panning)
- Stabilizes crop position within each "shot"
- Maintains 9:16 aspect ratio at 1080x1920

### 4. Hook Generation
- Extracts first frame from clip
- Generates TTS audio using OpenAI's voice API
- Creates intro scene with:
  - Blurred/dimmed first frame background
  - Centered hook text with yellow highlight
  - AI voiceover reading the hook
- Concatenates hook with main clip

### 5. Caption Generation
- Transcribes audio using OpenAI Whisper
- Creates ASS subtitle file with:
  - Word-by-word timing
  - Yellow highlight on current word
  - Black outline and semi-transparent background
- Burns captions into video using FFmpeg

## ğŸ¨ Caption Styling

The captions use CapCut-style formatting:

```
Font: Arial Black
Size: 70px
Color: White (#FFFFFF)
Highlight: Yellow (#00FFFF)
Outline: 4px Black
Shadow: 2px
Position: Lower third (350px from bottom)
```

## ğŸ› Troubleshooting

### Desktop App Issues

**1. "FFmpeg not found" or "yt-dlp not found"**
- Make sure `ffmpeg/ffmpeg.exe` and `yt-dlp.exe` are in the same folder as `AutoClipper.exe`

**2. "API key tidak valid"**
- Double-check your OpenAI or Azure OpenAI API key
- Ensure you have API credits available
- Check internet connection
- For Azure OpenAI, verify your Base URL format: `https://your-resource.openai.azure.com/openai/deployments/your-deployment-name`

**3. App won't start / crashes**
- Try running as Administrator
- Check if antivirus is blocking the app (add exception)
- Make sure you extracted all files from the zip

### CLI Version Issues

**1. "No Indonesian subtitle found"**
- The video might not have auto-generated Indonesian subtitles
- Try a different video or manually provide an SRT file

**2. "FFmpeg not found"**
- Ensure FFmpeg is installed and in your system PATH
- Run `ffmpeg -version` to verify

**3. "OpenAI API error"**
- Check your API key in `.env`
- Ensure you have sufficient API credits
- Verify internet connection
- For Azure OpenAI, verify all required environment variables are set correctly

**4. "Face detection not working"**
- Ensure OpenCV is properly installed
- The video might not have clear face visibility
- Try adjusting `minNeighbors` parameter in face detection

**5. "Whisper model download failed"**
- Check internet connection
- Try a smaller model size (tiny/base)
- Manually download model: `whisper --model base`

### Performance Tips

- Use `base` Whisper model for faster processing (vs `large`)
- Process videos under 2 hours for optimal memory usage
- Use SSD storage for faster video I/O
- Close other applications during processing

## ğŸ“Š API Usage & Costs

Estimated API costs per video (5 clips):

### OpenAI

| Feature | Model | Est. Cost |
|---------|-------|-----------|
| Highlight Detection | GPT-4.1 | ~$0.05-0.15 |
| TTS Voiceover | TTS-1 | ~$0.01/clip |
| Captions | Whisper API | ~$0.01/clip |

**Total estimate:** ~$0.10-0.25 per video (5 clips)

### Azure OpenAI

Pricing varies by Azure region and deployment tier. Check your Azure OpenAI pricing for:
- GPT-4 deployments (per 1K tokens)
- Speech Service (TTS) per character
- Whisper per audio hour

The desktop app shows real-time token usage and cost estimation during processing.

## ğŸ¤ Contributing

Contributions are welcome! Kami sangat menghargai kontribusi dari siapapun.

### ğŸ”¨ Building Desktop App from Source

Untuk developer yang ingin build .exe sendiri:

#### Prerequisites

```bash
# Install Python dependencies
cd desktop-app
pip install -r requirements.txt
pip install pyinstaller
```

#### Build Steps

```bash
# 1. Build exe dengan PyInstaller
cd desktop-app
pyinstaller build.spec

# 2. Output akan ada di: desktop-app/dist/AutoClipper.exe
```

#### Bundle External Dependencies

Setelah build, download dan copy file berikut ke folder `dist/`:

```
dist/
â”œâ”€â”€ AutoClipper.exe          # Hasil build
â”œâ”€â”€ ffmpeg/
â”‚   â”œâ”€â”€ ffmpeg.exe           # Download dari https://www.gyan.dev/ffmpeg/builds/
â”‚   â””â”€â”€ ffprobe.exe          # (pilih ffmpeg-release-essentials.zip)
â””â”€â”€ yt-dlp.exe               # Download dari https://github.com/yt-dlp/yt-dlp/releases
```

#### Download Links

| File | Download |
|------|----------|
| FFmpeg | [ffmpeg-release-essentials.zip](https://www.gyan.dev/ffmpeg/builds/) |
| yt-dlp | [yt-dlp.exe](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe) |

#### Final Package Size

```
AutoClipper.exe     ~50MB
ffmpeg/             ~80MB
yt-dlp.exe          ~10MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:              ~140MB
```

#### Testing Build

```bash
# Test dari source (development)
python desktop-app/app.py

# Test built exe
desktop-app/dist/AutoClipper.exe
```

---

### Quick Start untuk Kontributor

```bash
# 1. Fork repo ini (klik tombol Fork di GitHub)

# 2. Clone fork kamu
git clone https://github.com/USERNAME-KAMU/yt-short-clipper.git
cd yt-short-clipper

# 3. Tambahkan upstream remote
git remote add upstream https://github.com/OWNER/yt-short-clipper.git

# 4. Buat branch baru
git checkout -b feature/fitur-baru-kamu

# 5. Lakukan perubahan, lalu commit
git add .
git commit -m "feat: deskripsi perubahan"

# 6. Push ke fork kamu
git push origin feature/fitur-baru-kamu

# 7. Buat Pull Request di GitHub
```

### Cara Kontribusi

| Jenis | Deskripsi |
|-------|-----------|
| ğŸ› **Bug Report** | Laporkan bug di tab [Issues](../../issues) |
| ğŸ’¡ **Feature Request** | Request fitur baru di [Issues](../../issues) |
| ğŸ“– **Documentation** | Improve docs, fix typo, tambah contoh |
| ğŸ”§ **Code** | Fix bug, tambah fitur, improve performance |

ğŸ“š **Panduan lengkap ada di [CONTRIBUTING.md](CONTRIBUTING.md)** - termasuk tutorial Git untuk pemula!

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## âš ï¸ Disclaimer

- This tool is for personal/educational use only
- Respect YouTube's Terms of Service
- Ensure you have rights to use the content you're processing
- The AI-generated content should be reviewed before publishing

## ğŸ™ Acknowledgments

- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - YouTube downloading
- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [OpenCV](https://opencv.org/) - Computer vision
- [FFmpeg](https://ffmpeg.org/) - Video processing
- [OpenAI API](https://openai.com/) - GPT-4 and TTS
- [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service) - Azure-hosted OpenAI models

---

## ğŸ‘¨â€ğŸ’» Credits

Made with â˜• by **Aji Prakoso** for content creators

| | |
|---|---|
| ğŸ“ | [n8n & Automation eCourse](https://classroom.jipraks.com) |
| ğŸ“¸ | [@jipraks on Instagram](https://instagram.com/jipraks) |
| ğŸ¬ | [Aji Prakoso's YouTube](https://youtube.com/@jipraks) |
| ğŸŒ | [About Aji Prakoso](https://www.jipraks.com) |